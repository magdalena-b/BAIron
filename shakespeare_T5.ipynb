{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shakespeare-T5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bgU8Hf5ByMQ4wo5N8MxGaRE9Eb0EfSr-",
      "authorship_tag": "ABX9TyPeMRZJMbOROVB/kxD0bjS2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magdalena-b/Bairon/blob/master/shakespeare_T5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-sZdEJbSoT2"
      },
      "source": [
        "https://github.com/hetpandya/paraphrase-datasets-pretrained-models/blob/main/examples/t5_paraphrase_model_training_example.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0s2EGXZxpDZ"
      },
      "source": [
        "# **Shakespeare - Modern**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoa75FH5v7Px"
      },
      "source": [
        "!pip install simpletransformers datasets tqdm pandas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntqKi7iS1DZt"
      },
      "source": [
        "import csv\n",
        "\n",
        "shakespeare = open(\"shakespeare.txt\", \"r\", encoding=\"utf-8\")\n",
        "modern = open(\"modern.txt\", \"r\")\n",
        "\n",
        "\n",
        "with open(\"shakespeare.txt\") as textfile1, open(\"modern.txt\") as textfile2, open(\"parallel.csv\", \"w+\") as parallel: \n",
        "    writer = csv.writer(parallel, delimiter=\"\\t\")\n",
        "    writer.writerow([\"input_text\", \"target_text\", \"prefix\"])\n",
        "    for x, y in zip(textfile1, textfile2):\n",
        "        x = x.strip(\"\\n\")\n",
        "        y = y.strip(\"\\n\")\n",
        "        x = x.strip()\n",
        "        y = y.strip()\n",
        "        result = x + \"\\t\" + y + \"\\t\" + \"paraphrase\"\n",
        "        writer.writerow([x, y, \"paraphrase\"])\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPVm1XiXXc2A"
      },
      "source": [
        "import pandas\n",
        "shakespeare_df = pandas.read_csv(\"parallel.csv\", sep=\"\\t\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "N53QkW35a4_Y",
        "outputId": "9df4fe25-dbb8-40a9-ea9f-870b6cd15c34"
      },
      "source": [
        "shakespeare_df"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input_text</th>\n",
              "      <th>target_text</th>\n",
              "      <th>prefix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From fairest creatures we desire increase,</td>\n",
              "      <td>We want all beautiful creatures to reproduce t...</td>\n",
              "      <td>paraphrase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>That thereby beauty's rose might never die,</td>\n",
              "      <td>so that beauty’s flower will not die out;</td>\n",
              "      <td>paraphrase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>But as the riper should by time decrease,</td>\n",
              "      <td>but as an old man dies in time,</td>\n",
              "      <td>paraphrase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>His tender heir mught bear his memeory:</td>\n",
              "      <td>he leaves a young heir to carry on his memory.</td>\n",
              "      <td>paraphrase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>But thou, contracted to thine own bright eyes,</td>\n",
              "      <td>But you, concerned only with your own beautifu...</td>\n",
              "      <td>paraphrase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>866</th>\n",
              "      <td>Either not assail'd or victor being charged;</td>\n",
              "      <td>either not having been attacked by temptation ...</td>\n",
              "      <td>paraphrase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>Yet this thy praise cannot be so thy praise,</td>\n",
              "      <td>Yet, this praise of you cannot forever be so p...</td>\n",
              "      <td>paraphrase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868</th>\n",
              "      <td>To tie up envy evermore enlarged:</td>\n",
              "      <td>as to restrain envy, which is perpetually at l...</td>\n",
              "      <td>paraphrase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>869</th>\n",
              "      <td>If some suspect of ill mask'd not thy show,</td>\n",
              "      <td>If suspicion of sin did not cover your appearance</td>\n",
              "      <td>paraphrase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>870</th>\n",
              "      <td>Then thou alone kingdoms of hearts shouldst owe.</td>\n",
              "      <td>you would reign supreme in love over multitude...</td>\n",
              "      <td>paraphrase</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>871 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           input_text  ...      prefix\n",
              "0          From fairest creatures we desire increase,  ...  paraphrase\n",
              "1         That thereby beauty's rose might never die,  ...  paraphrase\n",
              "2           But as the riper should by time decrease,  ...  paraphrase\n",
              "3             His tender heir mught bear his memeory:  ...  paraphrase\n",
              "4      But thou, contracted to thine own bright eyes,  ...  paraphrase\n",
              "..                                                ...  ...         ...\n",
              "866      Either not assail'd or victor being charged;  ...  paraphrase\n",
              "867      Yet this thy praise cannot be so thy praise,  ...  paraphrase\n",
              "868                 To tie up envy evermore enlarged:  ...  paraphrase\n",
              "869       If some suspect of ill mask'd not thy show,  ...  paraphrase\n",
              "870  Then thou alone kingdoms of hearts shouldst owe.  ...  paraphrase\n",
              "\n",
              "[871 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ai-t4r76v2YC"
      },
      "source": [
        "from simpletransformers.t5 import T5Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sklearn"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT1Aq-gCvch7"
      },
      "source": [
        "train_data, test_data = train_test_split(shakespeare_df,test_size=0.1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxwIMSDJwWV_"
      },
      "source": [
        "args = {\n",
        "    \"reprocess_input_data\": True,\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"max_seq_length\": 256,\n",
        "    \"num_train_epochs\": 4,\n",
        "    \"num_beams\": None,\n",
        "    \"do_sample\": True,\n",
        "    \"top_k\": 50,\n",
        "    \"top_p\": 0.95,\n",
        "    \"use_multiprocessing\": False,\n",
        "    \"save_steps\": -1,\n",
        "    \"save_eval_checkpoints\": True,\n",
        "    \"evaluate_during_training\": False,\n",
        "    'adam_epsilon': 1e-08,\n",
        "    'eval_batch_size': 6,\n",
        "    'fp_16': False,\n",
        "    'gradient_accumulation_steps': 16,\n",
        "    'learning_rate': 0.0003,\n",
        "    'max_grad_norm': 1.0,\n",
        "    'n_gpu': 1,\n",
        "    'seed': 42,\n",
        "    'train_batch_size': 6,\n",
        "    'warmup_steps': 0,\n",
        "    'weight_decay': 0.0\n",
        "}"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Cx5aMq4waef"
      },
      "source": [
        "model = T5Model(\"t5\",\"t5-small\", args=args)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfkOswXKwgq7"
      },
      "source": [
        "model.train_model(train_data, eval_data=test_data, use_cuda=True,acc=sklearn.metrics.accuracy_score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XwYeGsiwqPy"
      },
      "source": [
        "from simpletransformers.t5 import T5Model\n",
        "from pprint import pprint\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX8y3aoGwsUg"
      },
      "source": [
        "root_dir = os.getcwd()\n",
        "trained_model_path = os.path.join(root_dir,\"outputs\")\n",
        "# trained_model_path = \"content/drive\"\n",
        "print(trained_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz4sTgQ5wuFr"
      },
      "source": [
        "args = {\n",
        "    \"overwrite_output_dir\": True,\n",
        "    \"max_seq_length\": 256,\n",
        "    \"max_length\": 50,\n",
        "    \"top_k\": 50,\n",
        "    \"top_p\": 0.95,\n",
        "    \"num_return_sequences\": 5,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFpvK3mBwwNU"
      },
      "source": [
        "trained_model = T5Model(\"t5\",trained_model_path,args=args)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPqMtZ1Mwy4K"
      },
      "source": [
        "prefix = \"paraphrase\"\n",
        "pred = trained_model.predict([f\"{prefix}: How are you?\"])\n",
        "pprint(pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}