{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bart_shakespeare.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMsUTj9P/xzLWIZriIbr31S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magdalena-b/Bairon/blob/master/bart_shakespeare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZTPfN496JPu"
      },
      "source": [
        "https://towardsdatascience.com/teaching-bart-to-rap-fine-tuning-hugging-faces-bart-model-41749d38f3ef\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh7c3Gzt20Zt",
        "outputId": "283c66f7-2a19-48cd-b4e8-55ce8ec9a854"
      },
      "source": [
        "!pip install -q pytorch-lightning\n",
        "!pip install -q transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 813 kB 31.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 118 kB 53.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.6 MB 52.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 234 kB 55.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 636 kB 27.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 829 kB 75.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 69.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 294 kB 54.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 142 kB 49.0 MB/s \n",
            "\u001b[?25h  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires tensorboard~=2.5, but you have tensorboard 2.4.1 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 16.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 30.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 29.1 MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s37Ev_j36EjO"
      },
      "source": [
        "import transformers\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split, RandomSampler, Dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "import math\n",
        "import random\n",
        "import re\n",
        "import argparse"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kML4XWjt6Svs",
        "outputId": "a8ba1dfb-540c-49d4-b2e9-5e720b214bd5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=False)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'bart_shakespeare/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suqiLDqc6boo"
      },
      "source": [
        "class LitModel(pl.LightningModule):\n",
        "\n",
        "  def __init__(self, learning_rate, tokenizer, model):\n",
        "    super().__init__()\n",
        "    self.learning_rate = learning_rate\n",
        "    self.tokenizer = tokenizer\n",
        "    self.model = model\n",
        "    self.eval_beams = 4\n",
        "\n",
        "    # if self.hparams.freeze_encoder:\n",
        "    freeze_params(self.model.get_encoder())\n",
        "\n",
        "    # if self.hparams.freeze_embeds:\n",
        "    self.freeze_embeds()\n",
        "\n",
        "\n",
        "  \n",
        "  def freeze_embeds(self):\n",
        "    ''' freeze the positional embedding parameters of the model; adapted from finetune.py '''\n",
        "    freeze_params(self.model.model.shared)\n",
        "    for d in [self.model.model.encoder, self.model.model.decoder]:\n",
        "      freeze_params(d.embed_positions)\n",
        "      freeze_params(d.embed_tokens)\n",
        "\n",
        "  # Do a forward pass through the model\n",
        "  def forward(self, input_ids, **kwargs):\n",
        "    return self.model(input_ids, **kwargs)\n",
        "  \n",
        "  def configure_optimizers(self):\n",
        "    optimizer = torch.optim.Adam(self.parameters(), lr = self.learning_rate)\n",
        "    return optimizer\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    # Load the data into variables\n",
        "    src_ids, src_mask = batch[0], batch[1]\n",
        "    tgt_ids = batch[2]\n",
        "    # Shift the decoder tokens right (but NOT the tgt_ids)\n",
        "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
        "\n",
        "    # Run the model and get the logits\n",
        "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
        "    lm_logits = outputs[0]\n",
        "    # Create the loss function\n",
        "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
        "    # Calculate the loss on the un-shifted tokens\n",
        "    loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
        "\n",
        "    return {'loss':loss}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "\n",
        "    src_ids, src_mask = batch[0], batch[1]\n",
        "    tgt_ids = batch[2]\n",
        "\n",
        "    decoder_input_ids = shift_tokens_right(tgt_ids, tokenizer.pad_token_id)\n",
        "    \n",
        "    # Run the model and get the logits\n",
        "    outputs = self(src_ids, attention_mask=src_mask, decoder_input_ids=decoder_input_ids, use_cache=False)\n",
        "    lm_logits = outputs[0]\n",
        "\n",
        "    ce_loss_fct = torch.nn.CrossEntropyLoss(ignore_index=self.tokenizer.pad_token_id)\n",
        "    val_loss = ce_loss_fct(lm_logits.view(-1, lm_logits.shape[-1]), tgt_ids.view(-1))\n",
        "\n",
        "    return {'loss': val_loss}\n",
        "  \n",
        "  # Method that generates text using the BartForConditionalGeneration's generate() method\n",
        "  def generate_text(self, text, eval_beams, early_stopping = True, max_len = 40):\n",
        "    ''' Function to generate text '''\n",
        "    generated_ids = self.model.generate(\n",
        "        text[\"input_ids\"],\n",
        "        attention_mask=text[\"attention_mask\"],\n",
        "        use_cache=True,\n",
        "        decoder_start_token_id = self.tokenizer.pad_token_id,\n",
        "        num_beams= eval_beams,\n",
        "        max_length = max_len,\n",
        "        early_stopping = early_stopping\n",
        "    )\n",
        "    return [self.tokenizer.decode(w, skip_special_tokens=True, clean_up_tokenization_spaces=True) for w in generated_ids]\n",
        "\n",
        "def freeze_params(model):\n",
        "  ''' Function that takes a model as input (or part of a model) and freezes the layers for faster training\n",
        "      adapted from finetune.py '''\n",
        "  for layer in model.parameters():\n",
        "    layer.requires_grade = False"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RGb93XM7qmX"
      },
      "source": [
        "# Create a dataloading module as per the PyTorch Lightning Docs\n",
        "class SummaryDataModule(pl.LightningDataModule):\n",
        "  def __init__(self, tokenizer, data_file, batch_size, num_examples = 20000):\n",
        "    super().__init__()\n",
        "    self.tokenizer = tokenizer\n",
        "    self.data_file = data_file\n",
        "    self.batch_size = batch_size\n",
        "    self.num_examples = num_examples\n",
        "  \n",
        "  # Loads and splits the data into training, validation and test sets with a 60/20/20 split\n",
        "  def prepare_data(self):\n",
        "    self.data = pd.read_csv(self.data_file)[:self.num_examples]\n",
        "    self.train, self.validate, self.test = np.split(self.data.sample(frac=1), [int(.6*len(self.data)), int(.8*len(self.data))])\n",
        "\n",
        "  # encode the sentences using the tokenizer  \n",
        "  def setup(self, stage):\n",
        "    self.train = encode_sentences(self.tokenizer, self.train['source'], self.train['target'])\n",
        "    self.validate = encode_sentences(self.tokenizer, self.validate['source'], self.validate['target'])\n",
        "    self.test = encode_sentences(self.tokenizer, self.test['source'], self.test['target'])\n",
        "\n",
        "  # Load the training, validation and test sets in Pytorch Dataset objects\n",
        "  def train_dataloader(self):\n",
        "    dataset = TensorDataset(self.train['input_ids'], self.train['attention_mask'], self.train['labels'])                          \n",
        "    train_data = DataLoader(dataset, sampler = RandomSampler(dataset), batch_size = self.batch_size)\n",
        "    return train_data\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    dataset = TensorDataset(self.validate['input_ids'], self.validate['attention_mask'], self.validate['labels']) \n",
        "    val_data = DataLoader(dataset, batch_size = self.batch_size)                       \n",
        "    return val_data\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    dataset = TensorDataset(self.test['input_ids'], self.test['attention_mask'], self.test['labels']) \n",
        "    test_data = DataLoader(dataset, batch_size = self.batch_size)                   \n",
        "    return test_data"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPq-Gx2m7vwA"
      },
      "source": [
        "hparams = argparse.Namespace()\n",
        "\n",
        "hparams.freeze_encoder = True\n",
        "hparams.freeze_embeds = True\n",
        "hparams.eval_beams = 4"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9wJy93870ku"
      },
      "source": [
        "def shift_tokens_right(input_ids, pad_token_id):\n",
        "  \"\"\" Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\n",
        "      This is taken directly from modeling_bart.py\n",
        "  \"\"\"\n",
        "  prev_output_tokens = input_ids.clone()\n",
        "  index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n",
        "  prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n",
        "  prev_output_tokens[:, 1:] = input_ids[:, :-1]\n",
        "  return prev_output_tokens\n",
        "\n",
        "def encode_sentences(tokenizer, source_sentences, target_sentences, max_length=32, pad_to_max_length=True, return_tensors=\"pt\"):\n",
        "  ''' Function that tokenizes a sentence \n",
        "      Args: tokenizer - the BART tokenizer; source and target sentences are the source and target sentences\n",
        "      Returns: Dictionary with keys: input_ids, attention_mask, target_ids\n",
        "  '''\n",
        "\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  target_ids = []\n",
        "  tokenized_sentences = {}\n",
        "\n",
        "  for sentence in source_sentences:\n",
        "    encoded_dict = tokenizer(\n",
        "          sentence,\n",
        "          max_length=max_length,\n",
        "          padding=\"max_length\" if pad_to_max_length else None,\n",
        "          truncation=True,\n",
        "          return_tensors=return_tensors,\n",
        "          add_prefix_space = True\n",
        "      )\n",
        "\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  input_ids = torch.cat(input_ids, dim = 0)\n",
        "  attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "\n",
        "  for sentence in target_sentences:\n",
        "    encoded_dict = tokenizer(\n",
        "          sentence,\n",
        "          max_length=max_length,\n",
        "          padding=\"max_length\" if pad_to_max_length else None,\n",
        "          truncation=True,\n",
        "          return_tensors=return_tensors,\n",
        "          add_prefix_space = True\n",
        "      )\n",
        "    # Shift the target ids to the right\n",
        "    # shifted_target_ids = shift_tokens_right(encoded_dict['input_ids'], tokenizer.pad_token_id)\n",
        "    target_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "  target_ids = torch.cat(target_ids, dim = 0)\n",
        "  \n",
        "\n",
        "  batch = {\n",
        "      \"input_ids\": input_ids,\n",
        "      \"attention_mask\": attention_masks,\n",
        "      \"labels\": target_ids,\n",
        "  }\n",
        "\n",
        "  return batch\n",
        "\n",
        "\n",
        "def noise_sentence(sentence_, percent_words, replacement_token = \"<mask>\"):\n",
        "  '''\n",
        "  Function that noises a sentence by adding <mask> tokens\n",
        "  Args: sentence - the sentence to noise\n",
        "        percent_words - the percent of words to replace with <mask> tokens; the number is rounded up using math.ceil\n",
        "  Returns a noised sentence\n",
        "  '''\n",
        "  # Create a list item and copy\n",
        "  sentence_ = sentence_.split(' ')\n",
        "  sentence = sentence_.copy()\n",
        "  \n",
        "  num_words = math.ceil(len(sentence) * percent_words)\n",
        "  \n",
        "  # Create an array of tokens to sample from; don't include the last word as an option because in the case of lyrics\n",
        "  # that word is often a rhyming word and plays an important role in song construction\n",
        "  sample_tokens = set(np.arange(0, np.maximum(1, len(sentence)-1)))\n",
        "  \n",
        "  words_to_noise = random.sample(sample_tokens, num_words)\n",
        "  \n",
        "  # Swap out words, but not full stops\n",
        "  for pos in words_to_noise:\n",
        "      if sentence[pos] != '.':\n",
        "          sentence[pos] = replacement_token\n",
        "  \n",
        "  # Remove redundant spaces\n",
        "  sentence = re.sub(r' {2,5}', ' ', ' '.join(sentence))\n",
        "  \n",
        "  # Combine concurrent <mask> tokens into a single token; this just does two rounds of this; more could be done\n",
        "  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
        "  sentence = re.sub(r'<mask> <mask>', \"<mask>\", sentence)\n",
        "  return sentence"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZVXD3ge73EN"
      },
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration, AdamW, BartConfig\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base', add_prefix_space=True)\n",
        "\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(\n",
        "    \"facebook/bart-base\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hK6S-MOAbe7"
      },
      "source": [
        "summary_data = SummaryDataModule(tokenizer, 'lyrics_simple_noised.csv', batch_size = 16, num_examples = 140000)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldNCZ4bPAstk"
      },
      "source": [
        "model = LitModel(learning_rate = 2e-5, tokenizer = tokenizer, model = bart_model)"
      ],
      "execution_count": 50,
      "outputs": []
    }
  ]
}